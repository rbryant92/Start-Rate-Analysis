{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An initiative in Q3 2022 was to investigate start rate performance for CTV, OTT, and video lineitems.   Start rate is defined as number of start events for a video ad divided by number of impressions served.  This was to address two primary concerns.  The first concern was over certain apps having unexpectedly poor start rate performance.   This contributes to the second concern, as start rate performance needs to be strong in order to run cost per completed view (CPCV) campaigns.   Over the course of this investigative analysis, we will utilize both internal and third party data.   Some data prior to the end of Q1 2022 have a bug where certain lineitems register start rates greater than 1.0, which is impossible by definition.   Therefore all analysis must investigate data from Q2 2022 or later.\n",
    "\n",
    "Things to look at:\n",
    "\n",
    "- Start rate of campaign_stats_rollup vs. raw impression\n",
    "- Look at evtEventQualityCodes distribution\n",
    "- Are these different for different serving groups/device types?\n",
    "\n",
    "We will look at event quality codes and create a logic where we eliminate invalid codes manually.  We will confirm this start rate matches (more closely) the start rates seen in CSR.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom line up front"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our top concern when we began to investigate start rate was why some of them were so low.\n",
    "- Previously, we found significant discrepancy between the campaign stats rollup (CSR) and the 3rd party rollup.   This was cause for concern.   CSR showed much lower start rates than the 3rd party rollup.\n",
    "- We later turned to raw impression data for clues.   A separate discrepancy was found in that notebook: there seemed to be discrepancy between CSR start events and start events in the raw impression data.   Again, we saw much higher start rate in raw impression data than in the CSR, which was due to event quality.\n",
    "- The event cleansing logic utilized in this notebook using a breakdown of quality codes in terms of powers of 2 was used to detect invalid start events.  While it is NOT PERFECT (sometimes off by fractions of a percentage point), there is now a much better and very close match between raw and CSR data, and this allows us to use data at the raw impression level to see if any particular impression level features (i.e. 'bidDeviceUserAgent' fields) are contributing to poor start rate.\n",
    "- A small number of event codes are causing over 90% of invalid start events.   These seem to be highly driven by the IP_MISMATCH code.   Summaries are presented to see proportions of how often each type of IP mismatch (bidIP, dirIP, and various eventIP's) occur, by browser, device, and exchange.\n",
    "- It is not clear how further to investigate third party start rates.  Because BEFORE the event cleansing logic on raw impressions, 3rd party was close to matching the raw impression data which counted invalid events, but then AFTER this event cleansing logic it was close to the CSR where this step has been applied, there is almost certainly a discrepancy in how invalid events are filtered out when third party data is rolled up.   I think we could validate this further if we had 3rd party impression data, but until then we may just be making educated guesses and may need to seek out additional feedback or data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform_toolkit as ptk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import plotly_express as px\n",
    "\n",
    "pd.set_option('display.max_columns',50)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptk.init_auth()\n",
    "conf = ptk.tshirt('xl')\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sc, ss, isp) = ptk.init_platform('start-rate-analysis', \n",
    "                                  env_archive=ptk.resolve_conda_env('analysis-preview-py3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import platform_toolkit_spark as pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the part of Amanda's script for timestamps - to ensure consistency as we load from the various datasets\n",
    "import minion.services.config as cfg\n",
    "import mpy.utils as utils\n",
    "from campaign_utils import minion as mu\n",
    "\n",
    "li = cfg.LineItemConfigClient()\n",
    "campaignClient = cfg.CampaignConfigClient()\n",
    "\n",
    "ts_1 = utils.now_unix_millis() - int(utils.DAY_MS*30)\n",
    "ts_2 = utils.now_unix_millis() + int(utils.DAY_MS*1)\n",
    "now_millis = utils.now_unix_millis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull impression and CSR data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset produced by https://streamsdash.valassisdigital.net/stream/4121\n",
    "\n",
    "isp.add_input_full(\n",
    "    dataset='impression2/campaign_stats_rollup',\n",
    "    root='REEF_TEAM_AE',\n",
    "    startTs = ts_1,\n",
    "    endTs = ts_2,\n",
    "    key='campaign-stats-rollup-final-stream'\n",
    ")\n",
    "campaign_stats = isp.source('campaign-stats-rollup-final-stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset produced by https://streamsdash.valassisdigital.net/stream/4150\n",
    "\n",
    "isp.add_input_full(\n",
    "    dataset='advertising-logs/impression',\n",
    "    root='REEF_IMPRESSION_DATA',\n",
    "    startTs = ts_1,\n",
    "    endTs = ts_2,\n",
    "    key='impression-final-stream'\n",
    ")\n",
    "impressions = isp.source('impression-final-stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset produced by https://streamsdash.valassisdigital.net/stream/36711622 - revisit later\n",
    "\n",
    "isp.add_input_full(\n",
    "    dataset='third-party-tagset/third_party_tagset_rollup',\n",
    "    root='PRODUCT_TP_TAGSET',\n",
    "    startTs = ts_1,\n",
    "    endTs = ts_2,\n",
    "    key='third-party-tagset-rollup-stream'\n",
    ")\n",
    "item_group_rollup = isp.source('third-party-tagset-rollup-stream')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pull from config service in order to join to the third party dataset.   The ts_1 and ts_2 timestamp filters may not work otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with li: \n",
    "    \n",
    "    # facets to include \n",
    "    LineItemConstants = li.Constants\n",
    "    cfg_types = cfg.load_service('Types')\n",
    "    \n",
    "    facets = (LineItemConstants.LINE_ITEM_BASICS_FACET |\n",
    "          LineItemConstants.LINE_ITEM_CAMPAIGN_FACET |\n",
    "          LineItemConstants.LINE_ITEM_SERVING_FACET |\n",
    "          LineItemConstants.LINE_ITEM_SERVING_GROUPS_FACET |\n",
    "          LineItemConstants.LINE_ITEM_SCORED_MAPS_FACET |\n",
    "          LineItemConstants.LINE_ITEM_CLIENT_IO_FACET |\n",
    "          LineItemConstants.LINE_ITEM_CLIENT_BENCHMARKS_FACET\n",
    "         )\n",
    "    \n",
    "    start_time_filter = cfg.minion_types.QueryFilter()\n",
    "    start_time_filter.field = li.Constants.FILTER_FIELD_START_TIME\n",
    "    start_time_filter.operation = cfg.minion_types.FILTER_OPERATION_GREATER_THAN_EQUALS\n",
    "    start_time_filter.values = [cfg.minion_types.ThriftValue(dateValue=ts_1)]\n",
    "    \n",
    "    end_time_filter = cfg.minion_types.QueryFilter()\n",
    "    end_time_filter.field = li.Constants.FILTER_FIELD_END_TIME\n",
    "    end_time_filter.operation = cfg.minion_types.FILTER_OPERATION_LESS_THAN_EQUALS\n",
    "    end_time_filter.values = [cfg.minion_types.ThriftValue(dateValue=ts_2)]\n",
    "    \n",
    "    state_filter = cfg.minion_types.QueryFilter()\n",
    "    state_filter.field = li.Constants.FILTER_FIELD_STATE\n",
    "    state_filter.operation = cfg.minion_types.FILTER_OPERATION_EQUALS\n",
    "    state_filter.values = [cfg.minion_types.ThriftValue(intValue=campaignClient.Types.ItemState.COMPLETED)]\n",
    "    \n",
    "    region_filter = cfg_types.QueryFilter(cfg.LineItemConfigClient.Constants.FILTER_FIELD_REGION_ID,\n",
    "                                      cfg.minion_types.FILTER_OPERATION_EQUALS,\n",
    "                                      [cfg.minion_types.ThriftValue(intValue=0)])\n",
    "    \n",
    "    filters = [start_time_filter, end_time_filter, state_filter, region_filter]\n",
    "        \n",
    "    line_item_config_list = []\n",
    "    line_chunk = li.fetchLineItemsByFiltersInChunks(facets, filters, previousItemId=0,\n",
    "                                                    chunkSize=1000, agentParamsToInclude={}).lineItems\n",
    "    line_item_config_list.extend(line_chunk)\n",
    "    \n",
    "    if len(line_chunk) > 1:\n",
    "        while True:\n",
    "            line_chunk = li.fetchLineItemsByFiltersInChunks(facets, filters, \n",
    "                                                            previousItemId=line_chunk[len(line_chunk) - 1].itemId,\n",
    "                                                            chunkSize=1000, agentParamsToInclude={}).lineItems\n",
    "            line_item_config_list.extend(line_chunk)\n",
    "            if len(line_chunk) < 1000:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dictionary with success metric (benchmark) names\n",
    "with cfg.ClientBenchmarkConfigClient() as cbcc:\n",
    "        benchmarks = cbcc.fetchSuccessMetricAttributes()\n",
    "success_metrics = {c:v.metricName for (c,v) in benchmarks.items()}\n",
    "\n",
    "def millis_to_dt(ts_millis):\n",
    "    \"\"\"\n",
    "    Convert millis into datetime\n",
    "    \"\"\"\n",
    "    return dt.datetime.fromtimestamp(ts_millis/1000.0)\n",
    "    \n",
    "def read_parameter(k, params):\n",
    "    if params.paramSetValues and k in params.paramSetValues:\n",
    "        return params.paramSetValues[k].paramValue\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def flight_length(start, end):\n",
    "    \"\"\"\n",
    "    Return length of flight in days, minimum of 1 day\n",
    "    \"\"\"\n",
    "    start_dt = millis_to_dt(start)\n",
    "    end_dt = millis_to_dt(end)\n",
    "    delta = end_dt - start_dt\n",
    "    return np.maximum(1,delta.days)\n",
    "    \n",
    "def extract_line_item_fields(li_config):\n",
    "    \"\"\"\n",
    "    Pull and process lineitem fields from config service\n",
    "    \"\"\"\n",
    "    line_item_id = li_config.itemId\n",
    "    state = li_config.itemBasics.state\n",
    "    media_type = cfg.LineItemConfigClient.Types.AdClass._VALUES_TO_NAMES[li_config.itemBasics.adClass]\n",
    "    product_id = li_config.itemClientIO.productId\n",
    "    start_time = li_config.itemBasics.startTime\n",
    "    end_time = li_config.itemBasics.endTime\n",
    "    flight_days = flight_length(start_time, end_time)\n",
    "    imp_goal = li_config.itemServing.impressions\n",
    "    placement_types = li_config.itemServing.placementType\n",
    "    is_mobile = li_config.itemServing.mobile\n",
    "    device_type = li_config.itemServing.deviceTypes\n",
    "    is_locationBased = li_config.itemServing.locationBased\n",
    "    \n",
    "    return (line_item_id, state, media_type, product_id, start_time, end_time, flight_days, imp_goal, \n",
    "            placement_types, is_mobile, device_type, is_locationBased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_item_config_extracted = [extract_line_item_fields(li) for li in line_item_config_list]\n",
    "\n",
    "li_config = pd.DataFrame(line_item_config_extracted, columns=['lineItemId', 'state', 'adClass', 'productId', \n",
    "                                                              'startTime', 'endTime', 'flightDays','impressionGoal', \n",
    "                                                              'placementType', 'isMobile', 'deviceType', \n",
    "                                                              'isLocationBased'])\n",
    "\n",
    "lineItems = [x.itemId for x in line_item_config_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulate the CSR to summarize impressions and start events\n",
    "campaign_stats_rollup = (campaign_stats\n",
    "                        .filter(F.col(\"lineItemId\").isin(lineItems))\n",
    "                        .filter(F.col('adWidth')==0)\n",
    "                        .filter(F.col('adHeight')==0)\n",
    "                        .withColumn('videoStart', F.col('eventCounts').getItem('start'))\n",
    "                        .groupby('lineItemId')\n",
    "                        .agg(F.sum('numImpressions').alias('sumImpressionsInternal'),\n",
    "                             F.sum('videoStart').alias('startEventsInternal'))\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulate 3rd party data to summarize impressions and start events\n",
    "item_group_rollup = (item_group_rollup\n",
    "                    .filter(F.col('size')=='0x0')\n",
    "                    .filter(F.col('vendorType')=='tag')\n",
    "                    .select(\"timevalueFrom\",\n",
    "                            \"timevalueTo\",\n",
    "                            \"eligibleItems\", \n",
    "                            \"numImpressions\", \n",
    "                            F.explode(\"miscFields\").alias(\"eventKey\", \"eventCountStr\"))\n",
    "                    .filter(F.lower(F.col(\"eventKey\")).isin([\"video plays\"]))\n",
    "                    .withColumn(\"eventCount\", F.col(\"eventCountStr\").cast(T.IntegerType()))\n",
    "                    .filter(F.size(\"eligibleItems\") == 1)\n",
    "                    .withColumn(\"lineItemId\", F.explode(\"eligibleItems\"))\n",
    "                    .filter(F.col(\"lineItemId\").isin(lineItems))\n",
    "                    .groupby('lineItemId')\n",
    "                    .agg(F.sum('numImpressions').alias('sumImpressionsThirdParty'),\n",
    "                         F.sum('eventCount').alias('startEventsThirdParty'))\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (ArrayType, StructType, StringType, StructField)\n",
    "\n",
    "# UDF for use in exploding the \"eventType\" and \"eventQuality\" fields at the same time\n",
    "combine = F.udf(lambda a, b, c, d, e: list(zip(a, b, c, d, e)),\n",
    "              ArrayType(StructType([StructField(\"eventType\", StringType()),\n",
    "                                    StructField(\"eventQuality\", StringType()),\n",
    "                                    StructField(\"evtIpFromRequest\", StringType()),\n",
    "                                    StructField(\"evtIpFromUrl\", StringType()),\n",
    "                                    StructField(\"evtRawIp\", StringType())])))\n",
    "\n",
    "# SDF for instances where there are start events\n",
    "startEventDF = (impressions\n",
    "                .filter(F.col('dirLineItemId').isin(lineItems))\n",
    "                .filter(F.col('impTrackingClass') > 0)\n",
    "                .withColumn('eventType', F.col('impEvents').getItem('evtEventType'))\n",
    "                .withColumn('eventQuality', F.col('impEvents').getItem('evtQuality'))\n",
    "                .withColumn('evtIpFromRequest', F.col('impEvents').getItem('evtIpFromRequest'))\n",
    "                .withColumn('evtIpFromUrl', F.col('impEvents').getItem('evtIpFromUrl'))\n",
    "                .withColumn('evtRawIp', F.col('impEvents').getItem('evtRawIp'))\n",
    "                .withColumn('new', combine('eventType', 'eventQuality', 'evtIpFromRequest', 'evtIpFromUrl', 'evtRawIp'))\n",
    "                .withColumn(\"new\", F.explode(\"new\"))\n",
    "                .select('dirLineItemId',\n",
    "                        'impServingGroupId',\n",
    "                        'bidIp',\n",
    "                        'dirIp',\n",
    "                        F.col('new.eventType').alias('eventType'),\n",
    "                        F.col('new.eventQuality').alias('eventQuality'),\n",
    "                        F.col('new.evtIpFromRequest').alias('evtIpFromRequest'),\n",
    "                        F.col('new.evtIpFromUrl').alias('evtIpFromUrl'),\n",
    "                        F.col('new.evtRawIp').alias('evtRawIp'),\n",
    "                        'bidUserAgentLookup')\n",
    "                .withColumnRenamed(\"dirLineItemId\", \"lineItemId\")\n",
    "                .filter(F.col('eventType') == 'start')\n",
    "                .withColumn(\"bidRtbDeviceType\", F.col(\"bidUserAgentLookup\").getItem(\"bidRtbDeviceType\"))\n",
    "                .withColumn(\"bidUserAgentScale\", F.col(\"bidUserAgentLookup\").getItem(\"bidUserAgentScale\"))\n",
    "                .withColumn(\"Flags\", F.col(\"bidUserAgentLookup\").getItem(\"Flags\"))\n",
    "                .withColumn(\"bidBrowserName\", F.col(\"bidUserAgentLookup\").getItem(\"bidBrowserName\"))\n",
    "                .withColumn(\"bidDeviceOS\", F.col(\"bidUserAgentLookup\").getItem(\"bidDeviceOS\"))\n",
    "                .withColumn(\"bidDeviceOSVersion\", F.col(\"bidUserAgentLookup\").getItem(\"bidDeviceOSVersion\"))\n",
    "                .withColumn(\"bidDeviceMake\", F.col(\"bidUserAgentLookup\").getItem(\"bidDeviceMake\"))\n",
    "                .drop(\"bidUserAgentLookup\")\n",
    "                .withColumn(\"eventQuality\", F.col(\"eventQuality\").cast(T.IntegerType()))\n",
    "               )\n",
    "\n",
    "# Need to convert this SDF to counts grouped by \"eventQuality\"\n",
    "startEventGrp = (startEventDF\n",
    "                .groupby('eventQuality')\n",
    "                .agg(F.count(\"*\").alias(\"eventTypeCount\"))\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need a separate SDF indicating impressions where there is NO start event\n",
    "# We will create a \"startEvent\" field and union this to the positive start event DF later\n",
    "nonStartDF = (impressions\n",
    "              .filter(F.col('dirLineItemId').isin(lineItems))\n",
    "              .filter(F.col('impTrackingClass') > 0)\n",
    "              .withColumn('eventType', F.col('impEvents').getItem('evtEventType'))\n",
    "              .withColumn('eventQuality', F.col('impEvents').getItem('evtQuality'))\n",
    "              .withColumn('evtIpFromRequest', F.col('impEvents').getItem('evtIpFromRequest'))\n",
    "              .withColumn('evtIpFromUrl', F.col('impEvents').getItem('evtIpFromUrl'))\n",
    "              .withColumn('evtRawIp', F.col('impEvents').getItem('evtRawIp'))\n",
    "              .select(\"dirLineItemId\",\n",
    "                      \"impServingGroupId\",\n",
    "                      \"bidIp\",\n",
    "                      \"dirIp\",\n",
    "                      \"evtIpFromRequest\",\n",
    "                      \"evtIpFromUrl\",\n",
    "                      \"evtRawIp\",\n",
    "                      \"eventType\",\n",
    "                      \"eventQuality\",\n",
    "                      \"bidUserAgentLookup\")\n",
    "              .withColumnRenamed(\"dirLineItemId\", \"lineItemId\")\n",
    "              .filter(~array_contains(col(\"eventType\"),\"start\"))\n",
    "              .withColumn(\"bidRtbDeviceType\", F.col(\"bidUserAgentLookup\").getItem(\"bidRtbDeviceType\"))\n",
    "              .withColumn(\"bidUserAgentScale\", F.col(\"bidUserAgentLookup\").getItem(\"bidUserAgentScale\"))\n",
    "              .withColumn(\"Flags\", F.col(\"bidUserAgentLookup\").getItem(\"Flags\"))\n",
    "              .withColumn(\"bidBrowserName\", F.col(\"bidUserAgentLookup\").getItem(\"bidBrowserName\"))\n",
    "              .withColumn(\"bidDeviceOS\", F.col(\"bidUserAgentLookup\").getItem(\"bidDeviceOS\"))\n",
    "              .withColumn(\"bidDeviceOSVersion\", F.col(\"bidUserAgentLookup\").getItem(\"bidDeviceOSVersion\"))\n",
    "              .withColumn(\"bidDeviceMake\", F.col(\"bidUserAgentLookup\").getItem(\"bidDeviceMake\"))\n",
    "              .drop(\"bidUserAgentLookup\", \"eventQuality\")\n",
    "              .withColumn(\"startEvent\", lit(\"None\"))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the grouped positive data frame to pandas to create invalid event code logic\n",
    "startEventPd = startEventGrp.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to break each code down in terms of the powers of 2 (including 2**0 = 1)\n",
    "invalidCodes = (0, 4, 128, 256, 512, 8192, 32768, 2097152)\n",
    "\n",
    "def bitBreak(x):\n",
    "    powers = []\n",
    "    i = 1\n",
    "    while i <= x:\n",
    "        if i & x:\n",
    "            powers.append(i)\n",
    "        i <<= 1\n",
    "    return powers\n",
    "\n",
    "# If an invalid code is included in the total breakdown for the quality code, the event is INVALID\n",
    "def validDefinition(x):\n",
    "    if any(c in invalidCodes for c in x):\n",
    "        result = \"Invalid\"\n",
    "    else:\n",
    "        result = \"Valid\"\n",
    "    return result\n",
    "\n",
    "# New function for ip mismatch specifically\n",
    "def ipMismatch(x):\n",
    "    if any(c == 512 for c in x):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    return result\n",
    "\n",
    "startEventPd[\"eventBreakdown\"] = startEventPd[\"eventQuality\"].apply(lambda x: bitBreak(x))\n",
    "startEventPd[\"startEvent\"] = startEventPd[\"eventBreakdown\"].apply(lambda x: validDefinition(x))\n",
    "startEventPd[\"ipMismatch\"] = startEventPd[\"eventBreakdown\"].apply(lambda x: ipMismatch(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the head of this DF\n",
    "startEventPd.sort_values(by = \"eventTypeCount\", ascending = False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentage of the time is this occurring??\n",
    "invalidEvents = startEventPd[startEventPd.startEvent == \"Invalid\"]\n",
    "ipMismatches = startEventPd[startEventPd.ipMismatch == True]\n",
    "\n",
    "total_invalid = invalidEvents.eventTypeCount.sum()\n",
    "total_mismatch = ipMismatches.eventTypeCount.sum()\n",
    "\n",
    "# Ratio\n",
    "total_mismatch / total_invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instances with the code 512 (IP_MISMATCH) are causing a tremendous number of start events to be invalid.  Many of these also have code 2 (BROWSER_ID_WEAK_MATCH) or code 64 (MID2_MISSING).   These codes appear to make up about >90% of invalid events; therefore, these are the low hanging fruit for which it may be worth seeing if they appear disproportionately for certain devices/browsers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this pandas df back to Spark with isolated necessary columns\n",
    "eventQualityLookup = ss.createDataFrame(startEventPd[[\"eventQuality\", \"eventBreakdown\", \"startEvent\"]])\n",
    "\n",
    "# Join this lookup table back to the original df - we will drop \"event quality\" and \"event breakdown\" after we look\n",
    "# at IP mismatches\n",
    "startEventDFwithLookup = (startEventDF\n",
    "                         .join(eventQualityLookup, on = \"eventQuality\")\n",
    "                         #.drop(\"eventQuality\", \"eventBreakdown\")\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now have a full reconstructed impression dataset - categorized with startEvent = None, Invalid, or Valid\n",
    "# We can get rid of the eventType and other fields to do this\n",
    "startEventDFwithLookup = startEventDFwithLookup.drop(\"eventType\", \"eventQuality\", \"eventBreakdown\")\n",
    "nonStartDF = nonStartDF.drop(\"eventType\")\n",
    "\n",
    "# Because we don't care about events that aren't starts, let's turn these variables into null strings\n",
    "nonStartDF = (nonStartDF\n",
    "             .withColumn('evtIpFromRequest', lit(None).cast(StringType()))\n",
    "             .withColumn('evtIpFromUrl', lit(None).cast(StringType()))\n",
    "             .withColumn('evtRawIp', lit(None).cast(StringType()))\n",
    "             )\n",
    "\n",
    "# Union all instead of union these datasets to bring them together and ensure identical rows are retained\n",
    "fullStartDF = (startEventDFwithLookup.unionAll(nonStartDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullStartDF = (fullStartDF\n",
    "              .withColumn(\"invalidStart\", F.when(fullStartDF.startEvent == \"Invalid\", 1).otherwise(0))\n",
    "              .withColumn(\"noStart\", F.when(fullStartDF.startEvent == \"None\", 1).otherwise(0))\n",
    "              .withColumn(\"validStart\", F.when(fullStartDF.startEvent == \"Valid\", 1).otherwise(0))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullStartDF = (fullStartDF\n",
    "              .withColumn(\"bidLiMismatch\", F.when(F.col(\"bidIp\") != F.col(\"dirIp\"), 1).otherwise(0))\n",
    "              .withColumn(\"liUrlMismatch\", F.when(F.col(\"dirIp\") != F.col(\"evtIpFromUrl\"), 1).otherwise(0))\n",
    "              .withColumn(\"liRawMismatch\", F.when(F.col(\"dirIp\") != F.col(\"evtRawIp\"), 1).otherwise(0))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullStartDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validBreakdown = (fullStartDF\n",
    "              .filter(F.col(\"validStart\") == 1)\n",
    "              .agg(F.count(\"*\").alias(\"totalCount\"),\n",
    "                   F.sum(\"bidLiMismatch\").alias(\"bidLiMismatches\"),\n",
    "                   F.sum(\"liUrlMismatch\").alias(\"liUrlMismatches\"),\n",
    "                   F.sum(\"liRawMismatch\").alias(\"liRawMismatches\")\n",
    "                  )\n",
    "               .withColumn(\"bidLiProp\", F.col(\"bidLiMismatches\") / F.col(\"totalCount\"))\n",
    "               .withColumn(\"liUrlProp\", F.col(\"liUrlMismatches\") / F.col(\"totalCount\"))\n",
    "               .withColumn(\"liRawProp\", F.col(\"liRawMismatches\") / F.col(\"totalCount\"))\n",
    "               .drop(\"bidLiMismatches\", \"bidRequestMismatches\", \"bidUrlMismatches\", \"bidRawMismatches\",\n",
    "                    \"liRequestMismatches\", \"liUrlMismatches\", \"liRawMismatches\")\n",
    "              )\n",
    "validBreakdown.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalidBreakdown = (fullStartDF\n",
    "              .filter(F.col(\"invalidStart\") == 1)\n",
    "              .agg(F.count(\"*\").alias(\"totalCount\"),\n",
    "                   F.sum(\"bidLiMismatch\").alias(\"bidLiMismatches\"),\n",
    "                   F.sum(\"liUrlMismatch\").alias(\"liUrlMismatches\"),\n",
    "                   F.sum(\"liRawMismatch\").alias(\"liRawMismatches\")\n",
    "                  )\n",
    "               .withColumn(\"bidLiProp\", F.col(\"bidLiMismatches\") / F.col(\"totalCount\"))\n",
    "               .withColumn(\"liUrlProp\", F.col(\"liUrlMismatches\") / F.col(\"totalCount\"))\n",
    "               .withColumn(\"liRawProp\", F.col(\"liRawMismatches\") / F.col(\"totalCount\"))\n",
    "               .drop(\"bidLiMismatches\", \"bidRequestMismatches\", \"bidUrlMismatches\", \"bidRawMismatches\",\n",
    "                    \"liRequestMismatches\", \"liUrlMismatches\", \"liRawMismatches\")\n",
    "              )\n",
    "invalidBreakdown.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief investigation of the IP mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reiterate, instances with IP mismatches (code 512) constitute a majority of invalid events which drive start rate performance lower.  We will look at the frequency of this occurrence by various other bid level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceTypes = (fullStartDF\n",
    "              .groupBy(\"bidRtbDeviceType\")\n",
    "              .agg(F.count(\"*\").alias(\"totalCount\"),\n",
    "                   F.sum(\"bidLiMismatch\").alias(\"bidLiMismatches\"),\n",
    "                   F.sum(\"liUrlMismatch\").alias(\"liUrlMismatches\"),\n",
    "                   F.sum(\"liRawMismatch\").alias(\"liRawMismatches\")\n",
    "                  )\n",
    "               .withColumn(\"bidLiProp\", F.col(\"bidLiMismatches\") / F.col(\"totalCount\"))\n",
    "               .withColumn(\"liUrlProp\", F.col(\"liUrlMismatches\") / F.col(\"totalCount\"))\n",
    "               .withColumn(\"liRawProp\", F.col(\"liRawMismatches\") / F.col(\"totalCount\"))\n",
    "               .drop(\"bidLiMismatches\", \"bidRequestMismatches\", \"bidUrlMismatches\", \"bidRawMismatches\",\n",
    "                    \"liRequestMismatches\", \"liUrlMismatches\", \"liRawMismatches\")\n",
    "              )\n",
    "deviceTypes = pts.to_pandas_parallel(deviceTypes)\n",
    "deviceTypes.sort_values(by = \"totalCount\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browserTypes = (fullStartDF\n",
    "              .groupBy(\"bidDeviceOS\")\n",
    "              .agg(F.count(\"*\").alias(\"totalCount\"),\n",
    "                   F.sum(\"bidLiMismatch\").alias(\"bidLiMismatches\"),\n",
    "                   F.sum(\"liUrlMismatch\").alias(\"liUrlMismatches\"),\n",
    "                   F.sum(\"liRawMismatch\").alias(\"liRawMismatches\")\n",
    "                  )\n",
    "               .withColumn(\"bidLiProp\", F.col(\"bidLiMismatches\") / F.col(\"totalCount\"))\n",
    "               .withColumn(\"liUrlProp\", F.col(\"liUrlMismatches\") / F.col(\"totalCount\"))\n",
    "               .withColumn(\"liRawProp\", F.col(\"liRawMismatches\") / F.col(\"totalCount\"))\n",
    "               .drop(\"bidLiMismatches\", \"bidRequestMismatches\", \"bidUrlMismatches\", \"bidRawMismatches\",\n",
    "                    \"liRequestMismatches\", \"liUrlMismatches\", \"liRawMismatches\")\n",
    "              )\n",
    "browserTypes = pts.to_pandas_parallel(browserTypes)\n",
    "browserTypes.sort_values(by = \"totalCount\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceMakes = (fullStartDF\n",
    "              .groupBy(\"bidDeviceMake\")\n",
    "              .agg(F.count(\"*\").alias(\"totalCount\"),\n",
    "                   F.sum(\"bidLiMismatch\").alias(\"bidLiMismatches\"),\n",
    "                   F.sum(\"liUrlMismatch\").alias(\"liUrlMismatches\"),\n",
    "                   F.sum(\"liRawMismatch\").alias(\"liRawMismatches\")\n",
    "                  )\n",
    "               .withColumn(\"bidLiProp\", F.col(\"bidLiMismatches\") / F.col(\"totalCount\"))\n",
    "               .withColumn(\"liUrlProp\", F.col(\"liUrlMismatches\") / F.col(\"totalCount\"))\n",
    "               .withColumn(\"liRawProp\", F.col(\"liRawMismatches\") / F.col(\"totalCount\"))\n",
    "               .drop(\"bidLiMismatches\", \"bidRequestMismatches\", \"bidUrlMismatches\", \"bidRawMismatches\",\n",
    "                    \"liRequestMismatches\", \"liUrlMismatches\", \"liRawMismatches\")\n",
    "              )\n",
    "deviceMakes = pts.to_pandas_parallel(deviceMakes)\n",
    "deviceMakes.sort_values(by = \"totalCount\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servingGroups = (fullStartDF\n",
    "                .groupBy(\"impServingGroupId\")\n",
    "                .agg(F.count(\"*\").alias(\"totalCount\"),\n",
    "                     F.sum(\"bidLiMismatch\").alias(\"bidLiMismatches\"),\n",
    "                     F.sum(\"liUrlMismatch\").alias(\"liUrlMismatches\"),\n",
    "                     F.sum(\"liRawMismatch\").alias(\"liRawMismatches\")\n",
    "                    )\n",
    "                 .withColumn(\"bidLiProp\", F.col(\"bidLiMismatches\") / F.col(\"totalCount\"))\n",
    "                 .withColumn(\"liUrlProp\", F.col(\"liUrlMismatches\") / F.col(\"totalCount\"))\n",
    "                 .withColumn(\"liRawProp\", F.col(\"liRawMismatches\") / F.col(\"totalCount\"))\n",
    "                 .drop(\"bidLiMismatches\", \"bidRequestMismatches\", \"bidUrlMismatches\", \"bidRawMismatches\",\n",
    "                      \"liRequestMismatches\", \"liUrlMismatches\", \"liRawMismatches\")\n",
    "                )\n",
    "servingGroups = pts.to_pandas_parallel(servingGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map exchange names\n",
    "serving_dict = mu.get_serving_group_dict()\n",
    "\n",
    "servingGroups['adExchangeName'] = servingGroups['impServingGroupId'].map(serving_dict)\n",
    "servingGroups.sort_values(by = \"totalCount\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps_line_level = (fullStartDF\n",
    "                  .groupby('lineItemId')\n",
    "                  .agg(F.count(\"*\").alias(\"countImpressionEvents\"),\n",
    "                       F.sum(\"validStart\").alias(\"countStartEvents\"))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startRateLI = campaign_stats_rollup.join(imps_line_level, on = \"lineItemId\")\n",
    "startRateLI = startRateLI.join(item_group_rollup, on = \"lineItemId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startRateLI.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startRateLI = pts.to_pandas_parallel(startRateLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns\n",
    "startRateLI[\"startRateInternal\"] = startRateLI[\"startEventsInternal\"] / startRateLI[\"sumImpressionsInternal\"]\n",
    "startRateLI[\"rawStartRate\"] = startRateLI[\"countStartEvents\"] / startRateLI[\"countImpressionEvents\"]\n",
    "startRateLI[\"startRateThirdParty\"] = startRateLI[\"startEventsThirdParty\"] / startRateLI[\"sumImpressionsThirdParty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get rid of lineitems with <1000 impressions for this... these are probably test items\n",
    "startRateLI = startRateLI[startRateLI.sumImpressionsInternal > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startRateLI.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startRateLI.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start rate discrepancy - investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks at our data in its totality, so that we can compare the three data sources: raw, CSR, and third party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(startRateLI, x=\"sumImpressionsInternal\", y=\"countImpressionEvents\", log_x = False,\n",
    "                 log_y = False, hover_data=['lineItemId'], title = \"Internal vs. Raw Impressions\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(startRateLI, x=\"startEventsInternal\", y=\"countStartEvents\", log_x = False,\n",
    "                 log_y = False, hover_data=['lineItemId'], title = \"Internal vs. Raw Impression Data Start Events\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(startRateLI, x=\"startRateInternal\", y=\"rawStartRate\", log_x = False,\n",
    "                 log_y = False, hover_data=['lineItemId'], title = \"Internal vs. Raw Impression Start Rate\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(startRateLI, x=\"sumImpressionsThirdParty\", y=\"countImpressionEvents\", log_x = False,\n",
    "                 log_y = False, hover_data=['lineItemId'], \n",
    "                 title = \"3rd Party vs. Raw Impressions\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(startRateLI, x=\"countStartEvents\", y=\"startEventsThirdParty\", log_x = True,\n",
    "                 log_y = True, hover_data=['lineItemId'], title = \"Internal vs. 3rd Party Start Events\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [ analysis-preview-py3 ]",
   "language": "python",
   "name": "analysis-preview-py3-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
